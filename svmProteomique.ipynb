{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svmProteomique",
      "provenance": [],
      "authorship_tag": "ABX9TyPWXYc7dD/ARiKPOBY+N0R8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samibahig/RecoverProject/blob/main/svmProteomique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wii64H9RLaI6",
        "outputId": "69d8abd0-3835-4e32-fa41-5a6cabf8b77f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle as pkl\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import os\n",
        "plt.style.use('ggplot')\n",
        "#print('\\nMETADATA :')\n",
        "data_path = ''\n",
        "metadata_filename = data_path + '/content/metadata.csv'\n",
        "meta_df = pd.read_csv(metadata_filename)\n",
        "#print(meta_df.columns)\n",
        "meta_df.columns = ['#', 'plate', '-', 'symptoms'] + list(meta_df)[4:]\n",
        "#print(meta_df.columns)\n",
        "#print('available metadata :', list(meta_df))\n",
        "meta_idx = meta_df['ID'].to_list()\n",
        "meta_label = meta_df['symptoms'].to_list()\n",
        "#print('------------------')\n",
        "#print(list(zip(meta_idx, meta_label)))\n",
        "#print('------------------')\n",
        "meta_id_label_dict = {str(k): 1 if v=='S' else 0 for k, v in zip(meta_idx, meta_label)}\n",
        "data_path = ''\n",
        "\n",
        "#DF1 : proteomics\n",
        "#print('\\nPROEOMICS DATA :')\n",
        "proteomics_data_filename = '/content/proteomics.csv'\n",
        "\n",
        "dim_df = pd.read_csv(proteomics_data_filename, nrows=1)\n",
        "#print('--------')\n",
        "#print(dim_df)\n",
        "#print('--------')\n",
        "dim = len(list(dim_df))\n",
        "#print(dim)\n",
        "#print('------------')\n",
        "print('# of columns in source csv file :', dim)\n",
        "all_cols = [i for i in range(dim)]\n",
        "\n",
        "print('--------')\n",
        "feat_cols = all_cols[1:-4]\n",
        "print(feat_cols)\n",
        "print('--------')\n",
        "samplesidx_col = [0]\n",
        "\n",
        "feat_df = pd.read_csv(proteomics_data_filename, skiprows=4, nrows=1, dtype=str, usecols=feat_cols)\n",
        "features = list(feat_df)\n",
        "print('# of features : ', len(features))\n",
        "print('first feature :', features[0])\n",
        "print('last feature :', features[-1])\n",
        "\n",
        "idx_df = pd.read_csv(proteomics_data_filename, skiprows=6, index_col=0, skipfooter=4, usecols=[0], engine='python')\n",
        "idx = list(idx_df.index.values)\n",
        "print('# of idx : ', len(idx))\n",
        "print('first id :', idx[0])\n",
        "print('last id :', idx[-1])\n",
        "\n",
        "df1 = pd.read_csv(proteomics_data_filename, skiprows=6, dtype=np.float32, skipfooter=4, usecols=feat_cols, engine='python')\n",
        "assert df1.shape[0] == len(idx)\n",
        "assert df1.shape[1] == len(features)\n",
        "\n",
        "df1['idx'] = idx\n",
        "df1.set_index('idx', inplace=True)\n",
        "df1.columns = features\n",
        "print('# of Nan values :', df1.isna().sum().sum())\n",
        "\n",
        "#clean data of samples that are not in metadata :\n",
        "idx = df1.index.values\n",
        "y = []\n",
        "for k in range(len(idx)):\n",
        "    id = idx[k]\n",
        "    if id in meta_id_label_dict:\n",
        "        y.append(meta_id_label_dict[id])\n",
        "    else:\n",
        "        # we will not put this sample in the dataset\n",
        "        #print('sample to remove because of unknown label:', k, id)\n",
        "        y.append('to_remove')\n",
        "df1['label'] = y\n",
        "df1 = df1[df1.label != 'to_remove']\n",
        "\n",
        "#create X and y matrices for ML :\n",
        "y = list(df1['label'])\n",
        "del df1['label']\n",
        "print('---------')\n",
        "print(df1)\n",
        "print('---------')\n",
        "X = df1.to_numpy()\n",
        "print('proteomics data :')\n",
        "print('# of samples : ', df1.shape[0])\n",
        "print('# of features : ', df1.shape[1])\n",
        "print('labels:', list(dict.fromkeys(y)))\n",
        "\n",
        "\n",
        "## save X and y in pickles if you want :\n",
        "##data_name = 'recover_multiomics_'\n",
        "##feat_dict = {k: str(v) for k, v in zip(range(len(list(df))), list(df))}\n",
        "##with open(data_path + data_name + 'feat_dict', 'wb') as fo:\n",
        "##    pkl.dump(feat_dict, fo)\n",
        "##with open(data_path + data_name + 'X', 'wb') as fo:df\n",
        "##            pkl.dump(X, fo)\n",
        "##with open(data_path + data_name + 'y', 'wb') as fo:\n",
        "##            pkl.dump(y, fo)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of columns in source csv file : 189\n",
            "--------\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184]\n",
            "--------\n",
            "# of features :  184\n",
            "first feature : Q96SB3\n",
            "last feature : P09603\n",
            "# of idx :  104\n",
            "first id : 5-139\n",
            "last id : 3-043\n",
            "# of Nan values : 0\n",
            "---------\n",
            "        Q96SB3   P16278   O75475   Q05516  ...  P05113.1   P00813   P01374    P09603\n",
            "idx                                        ...                                      \n",
            "5-139  1.61741  1.31276  3.20077  1.28369  ...   0.12752  5.46542  5.97368  10.40443\n",
            "1-039  2.79530  2.12398  2.90156  1.55239  ...   0.88631  5.24029  5.07646  10.14180\n",
            "1-062  1.69202  2.07015  2.07562  0.85847  ...   0.18121  5.34243  4.89149  10.02279\n",
            "1-040  1.62496  1.67346  2.30191  1.09831  ...   2.11383  5.54121  5.57492  10.13417\n",
            "2-044  1.69246  1.94635  1.87725  0.84233  ...   0.60991  4.98001  4.80933  10.04586\n",
            "...        ...      ...      ...      ...  ...       ...      ...      ...       ...\n",
            "1-073  1.40763  2.32194  2.53494  0.55014  ...   0.31641  5.31388  4.78352  10.50358\n",
            "2-108  1.73766  1.44918  2.23165  0.44999  ...   0.37494  5.44716  5.22955  10.13842\n",
            "5-114  2.94638  1.45486  3.31485  0.93572  ...   2.98474  5.34230  5.30634  10.16184\n",
            "5-075  2.09489  2.70359  2.17787  1.16964  ...   0.76538  5.14975  5.37112  10.40146\n",
            "3-043  2.23329  2.41564  3.45536  0.91918  ...   0.87126  5.34694  5.08457  10.35240\n",
            "\n",
            "[100 rows x 184 columns]\n",
            "---------\n",
            "proteomics data :\n",
            "# of samples :  100\n",
            "# of features :  184\n",
            "labels: [1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nch2nIP1mpE"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "import numpy as np"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3MzYofQ1n3n"
      },
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Yz9P0gz-N8",
        "outputId": "4e077021-0586-4df2-a81c-dca6830bdbb2"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(predictions, y_test))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgOZHYvEFbSG",
        "outputId": "ce3bbb58-1fdd-4d8f-84a1-cc2dea2b9bcf"
      },
      "source": [
        "from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(clf.get_params())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'C': 1.0,\n",
            " 'break_ties': False,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'scale',\n",
            " 'kernel': 'linear',\n",
            " 'max_iter': -1,\n",
            " 'probability': False,\n",
            " 'random_state': None,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaHfreMU0LtV",
        "outputId": "723f2823-50b9-49c9-cdae-b22a633b32d0"
      },
      "source": [
        "#### Bootstrapping ####\n",
        "########################################################\n",
        "# Creating empty list to hold accuracy values\n",
        "AccuracyValues=[]\n",
        "n_times=60\n",
        "## Performing bootstrapping\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "for i in range(n_times):\n",
        "    #Split the data into training and testing set\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    # Changing the seed value for each iteration\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+i)\n",
        "    result = svm.SVC(kernel='linear')\n",
        "    result.fit(X_train, y_train)\n",
        "    ########################################################\n",
        "    predictions = result.predict(X_test)\n",
        "    Accuracy=metrics.accuracy_score(y_test, predictions)\n",
        "    print(Accuracy)\n",
        "    AccuracyValues.append((Accuracy))\n",
        "    #print(Accuracy)\n",
        "    print(AccuracyValues)\n",
        "\n",
        "###### Single Decision Tree Regression in Python #######\n",
        "    #choose from different tunable hyper parameters\n",
        "    #RegModel = tree.DecisionTreeRegressor(max_depth=3,criterion='mse')\n",
        " \n",
        "    #Creating the model on Training Data\n",
        "    #DTree=RegModel.fit(X_train,y_train)\n",
        "    #prediction=DTree.predict(X_test)\n",
        " \n",
        "    #Measuring accuracy on Testing Data\n",
        "#Accuracy=100- (np.mean(np.abs((y_test - prediction) / y_test)) * 100)\n",
        "    \n",
        "    # Storing accuracy values\n",
        "#AccuracyValues.append(np.round(Accuracy))\n",
        "    \n",
        "################################################\n",
        "# Result of all bootstrapping trials\n",
        "print(AccuracyValues)\n",
        " \n",
        "# Final accuracy\n",
        "print('Final average accuracy', np.mean(AccuracyValues), 'std', np.std(AccuracyValues))\n",
        "#print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_final ))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45\n",
            "[0.45]\n",
            "0.5\n",
            "[0.45, 0.5]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65]\n",
            "0.3\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6]\n",
            "0.75\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55, 0.55]\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55, 0.55]\n",
            "Final average accuracy 0.48833333333333334 std 0.10620995977569879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKdKCo-UWnd6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import svm"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6wMdXH4bV69"
      },
      "source": [
        "#from sklearn import svm\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = svm.SVC()\n",
        "#accuracy = cross_val_score(model, X_train, y_train, scoring='accuracy', cv = 10)\n",
        "#print(accuracy)\n",
        "#print(\"Accuracy of Model with Cross Validation is:\",accuracy.mean() * 100)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geiZxeeRDcVr",
        "outputId": "51ae281c-8854-4f69-956d-ba78aca08ca8"
      },
      "source": [
        "from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(model.get_params())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'C': 1.0,\n",
            " 'break_ties': False,\n",
            " 'cache_size': 200,\n",
            " 'class_weight': None,\n",
            " 'coef0': 0.0,\n",
            " 'decision_function_shape': 'ovr',\n",
            " 'degree': 3,\n",
            " 'gamma': 'scale',\n",
            " 'kernel': 'rbf',\n",
            " 'max_iter': -1,\n",
            " 'probability': False,\n",
            " 'random_state': None,\n",
            " 'shrinking': True,\n",
            " 'tol': 0.001,\n",
            " 'verbose': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I_Ill0BFtHt",
        "outputId": "0adfe249-9f9a-4157-9538-be5fc92ac7b1"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(result.set_params())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YODhdjzfM49M",
        "outputId": "b147f478-2b09-43be-dee3-03255e963e70"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from pprint import pprint\n",
        "# Number of trees in random forest\n",
        "kernel = ['linear', 'poly', 'rbf', 'sigmoid'] #[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "C = [0.1, 1, 10, 100, 1000] #['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "gamma = [0.1, 1, 10, 100] #[int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "#max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "degree = [0, 1, 2, 3, 4, 5, 6]\n",
        "# Minimum number of samples required at each leaf node\n",
        "# Method of selecting samples for training each tree\n",
        "# Create the random grid\n",
        "random_grid = {'kernel': kernel,\n",
        "               'C': C,\n",
        "               'gamma': gamma,\n",
        "               'degree': degree}\n",
        "pprint(random_grid)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': [0.1, 1, 10, 100, 1000],\n",
            " 'degree': [0, 1, 2, 3, 4, 5, 6],\n",
            " 'gamma': [0.1, 1, 10, 100],\n",
            " 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w4_oHf0evUg",
        "outputId": "bf6eb2de-239c-4cd3-9097-18b0bff14294"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "tree_clf = svm.SVC()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "clf = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 200, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "clf.fit(X_train, y_train)\n",
        "#rnd_search_cv.best_estimator_\n",
        "#param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
        "#rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)\n",
        "#y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
        "#accuracy_score(y_train, y_pred)\n",
        "#y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
        "#accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 907 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done 997 out of 1000 | elapsed:    2.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    2.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                                 class_weight=None, coef0=0.0,\n",
              "                                 decision_function_shape='ovr', degree=3,\n",
              "                                 gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                                 probability=False, random_state=None,\n",
              "                                 shrinking=True, tol=0.001, verbose=False),\n",
              "                   iid='deprecated', n_iter=200, n_jobs=-1,\n",
              "                   param_distributions={'C': [0.1, 1, 10, 100, 1000],\n",
              "                                        'degree': [0, 1, 2, 3, 4, 5, 6],\n",
              "                                        'gamma': [0.1, 1, 10, 100],\n",
              "                                        'kernel': ['linear', 'poly', 'rbf',\n",
              "                                                   'sigmoid']},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOfwivRQFnL9",
        "outputId": "614e306a-927e-44fe-ad87-416f614320ae"
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'degree': 6, 'gamma': 100, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MpUFlrdKLfd"
      },
      "source": [
        "### Nouvelle instantiation du svm.SVC avec les paramètres trouvés en Cross-Validation\n",
        "result = svm.SVC(C = 10, degree = 6, gamma = 100, kernel = 'linear')"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvIlLrnLKPf2",
        "outputId": "0b68e4fc-0fda-4e2e-c084-604c206fa3c1"
      },
      "source": [
        "### entraînement du modèle avec les paramètres trouvés en Cross-Validation\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "result.fit(X_train, y_train)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=6, gamma=100, kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjDr2wfOKS_a",
        "outputId": "036a5456-ba95-4af1-b167-02a4381c22df"
      },
      "source": [
        "### Calcul de y_test et de l'accuracy \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "predictions = result.predict(X_test)\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3SwXBsEKdKC",
        "outputId": "de820475-fbb8-4ecd-c2fd-09d170c33a1c"
      },
      "source": [
        "### Vérification avec f1_score\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, predictions)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42105263157894735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJO_EH1yKeCp",
        "outputId": "afeac166-72ea-4882-bb1c-b83a83717f18"
      },
      "source": [
        "### Boostraping 60 fois avec Paramètres obtenus en Cross-Validation\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "#### Bootstrapping ####\n",
        "########################################################\n",
        "# Creating empty list to hold accuracy values\n",
        "AccuracyValues=[]\n",
        "n_times=60\n",
        "## Performing bootstrapping\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split \n",
        "for i in range(n_times):\n",
        "    #Split the data into training and testing set\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    # Changing the seed value for each iteration\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+i)\n",
        "    result = svm.SVC(C = 10, degree = 6, gamma = 100, kernel = 'linear')\n",
        "    result.fit(X_train, y_train)\n",
        "    ########################################################\n",
        "    prediction = result.predict(X_test)\n",
        "    Accuracy=metrics.accuracy_score(y_test, prediction)\n",
        "    print(Accuracy)\n",
        "    AccuracyValues.append((Accuracy))\n",
        "    #print(Accuracy)\n",
        "    print(AccuracyValues)\n",
        "    \n",
        "    #Creating the model on Training Data\n",
        "    #DTree=RegModel.fit(X_train,y_train)\n",
        "    #prediction=DTree.predict(X_test)\n",
        " \n",
        "    #Measuring accuracy on Testing Data\n",
        "#Accuracy=100- (np.mean(np.abs((y_test - prediction) / y_test)) * 100)\n",
        "    \n",
        "    # Storing accuracy values\n",
        "#AccuracyValues.append(np.round(Accuracy))\n",
        "    \n",
        "################################################\n",
        "# Result of all bootstrapping trials\n",
        "print(AccuracyValues)\n",
        " \n",
        "# Final accuracy\n",
        "print('Final average accuracy',np.mean(AccuracyValues), ' std ', np.std(AccuracyValues))\n",
        "#print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_final ))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45\n",
            "[0.45]\n",
            "0.5\n",
            "[0.45, 0.5]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65]\n",
            "0.3\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55]\n",
            "0.7\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35]\n",
            "0.4\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55]\n",
            "0.65\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5]\n",
            "0.45\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45]\n",
            "0.6\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6]\n",
            "0.75\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75]\n",
            "0.35\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35]\n",
            "0.5\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55]\n",
            "0.55\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55, 0.55]\n",
            "[0.45, 0.5, 0.35, 0.45, 0.35, 0.7, 0.55, 0.35, 0.5, 0.6, 0.4, 0.7, 0.55, 0.55, 0.5, 0.65, 0.3, 0.6, 0.35, 0.35, 0.5, 0.4, 0.45, 0.4, 0.45, 0.55, 0.7, 0.4, 0.4, 0.45, 0.6, 0.4, 0.4, 0.45, 0.45, 0.4, 0.4, 0.55, 0.6, 0.55, 0.4, 0.65, 0.35, 0.4, 0.45, 0.35, 0.45, 0.45, 0.55, 0.65, 0.55, 0.5, 0.45, 0.6, 0.75, 0.35, 0.5, 0.55, 0.55, 0.55]\n",
            "Final average accuracy 0.48833333333333334  std  0.10620995977569879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcPuGRSFUPP-",
        "outputId": "8b52c6e0-e868-4f08-9186-455e5de11c6d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, prediction)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 5],\n",
              "       [4, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "0q9zjJWaP_ck",
        "outputId": "44c9f993-741a-4261-a3c1-774bfb90ec3c"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import randint, uniform\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "C = randint(low=1,high=100)\n",
        "#param_grid = {'kernel':['rbf', 'poly'], 'C': np.random.randint(low=1,high=100), 'gamma': uniform(loc=0, scale=1)}\n",
        "param_grid = {'kernel': ['poly', 'rbf', 'linear'], 'degree':[2], 'C': [1, 10]}\n",
        "#result = svm.SVC(C = 1, degree = 2, gamma = 0.1, kernel = 'poly')\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(svm.SVC(), param_grid, cv=10)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)\n",
        "import pandas as pd\n",
        "pvt = pd.pivot_table(pd.DataFrame(grid.cv_results_),\n",
        "    values='mean_test_score', index='param_kernel', columns='param_C')\n",
        "ax = sns.heatmap(pvt)\n",
        "plt.show()\n",
        "#C = 1, degree = 2, gamma = 0.1, kernel = 'poly'"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'kernel': ['poly', 'rbf', 'linear'], 'degree': [2], 'C': [1, 10]}\n",
            "Best cross-validation score: 0.64\n",
            "Best parameters:  {'C': 10, 'degree': 2, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9U8DRRl0Qhn"
      },
      "source": [
        "from scipy.stats import randint, uniform\n",
        "distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])"
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}